{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6e5a12",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f00c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "import warnings\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import lasso_path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import re\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "simplefilter(action='ignore', category=DataConversionWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import xgboost as xgb\n",
    "    \n",
    "from collections import Counter\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900564c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinitialize():\n",
    "    '''\n",
    "    Used to initialize the datasets of predictors and dependent and rename the columns\n",
    "    '''\n",
    "    \n",
    "    to_search = ['US', 'SENT', 'unc_bex', 'ra_bex', 'VIX', 'mcsi', r'slope\\B', r'point0\\b', 'convex']\n",
    "    \n",
    "    data = pd.read_excel(\"Data for ML.xlsx\", header=0, parse_dates=['DateStru'], index_col=[1])\n",
    "    \n",
    "    Y = data.filter(like='logret')\n",
    "    X = data.loc[:, data.columns.to_series().str.contains(\"|\".join(to_search))]\n",
    "    X = X.rename(columns={\"USTBILLSECMARKET3MONTHDMIDDLERATE\": \"T-Bill\", \n",
    "                  \"unc_bex_AnnualVolPercentage\": \"unc_bex_%\", \n",
    "                  \"USInstitutional\": \"USInst\",\n",
    "                  \"USIndividual\": \"USInd\"})\n",
    "    return X, Y\n",
    "\n",
    "X, Y = reinitialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144c7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dictionary with last observation available for test set\n",
    "upp_bound = {x: Y[Y[x].isna()].index[0] - pd.to_timedelta(1, unit='w') for x in Y.columns[1:]} \n",
    "upp_bound[\"logret_1week\"] = pd.to_datetime(\"2015-12-12\")\n",
    "\n",
    "# dictionary with first observation available for test set\n",
    "interm_bound = {x: Y[Y[x].isna()].index[0] - pd.to_timedelta(53, unit='w') for x in Y.columns[1:]}\n",
    "\n",
    "# dictionary with first observation available for evaluation set\n",
    "#low_bound = {x: Y[Y[x].isna()].index[0] - pd.to_timedelta(53*2, unit='w') for x in Y.columns[1:]}\n",
    "\n",
    "\n",
    "# important subsets for variables\n",
    "pricing_kernel = ['point0', 'slopem2', 'slopep2', 'slopem5', 'slopep5', 'slopem10', 'slopep10', 'convexp2', 'convexm2']\n",
    "except_kernel = [x for x in X.columns.to_list() if x not in pricing_kernel]  # only small gains if not including pricing kernel in standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db1f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(name, start_time=None):\n",
    "    '''\n",
    "    Used to keep track of the time (in general, in particular for hypterparameter tuning)\n",
    "    '''\n",
    "    if not start_time:\n",
    "        start_time=datetime.datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.datetime.now()-start_time).total_seconds(),3600)\n",
    "        tmin, tsec = divmod(temp_sec,60)\n",
    "        print(\"Execution time for\", name, \"is \", thour,\" h :\", tmin,' m :', round(tsec,2), \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030f1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually throughout the model implementations I used normal R2\n",
    "# the reason is that the demeaned R2 is highly susceptible to standardization of the dependent\n",
    "# and it did not seem to me a 'robust' metric to evaluate\n",
    "\n",
    "# since I worked a lot on the standardizations, I used the normal R2 but for every function in evaluation\n",
    "# there is a parameter 'score' that can be set to True and both the models and the metric collected\n",
    "# will be Demeaned R2\n",
    "\n",
    "def impl_r2(actual, predicted):\n",
    "    '''\n",
    "    Implemented R^2 computations corrected as in the paper (with the denominator not demeaned), \n",
    "    used to be comparable to the literature (even if we are at the market level and not in a panel of individual stocks)\n",
    "    '''\n",
    "    actual, predicted = np.array(actual), np.array(predicted)\n",
    "    num = 0.0\n",
    "    denom = 0.0 \n",
    "    num = ((actual - predicted)**2).sum()\n",
    "    denom = ((actual)**2).sum()  \n",
    "    R2 = 1-(num/denom)\n",
    "    return R2\n",
    "\n",
    "impl_score = make_scorer(impl_r2, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0844afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yr_map(df, year, lq=True):\n",
    "    '''\n",
    "    Function to segment datasets on the basis of year (used below)\n",
    "    '''\n",
    "    if lq:\n",
    "        result = df.loc[df.index.year <= year, :].copy(deep=True)\n",
    "    else:\n",
    "        result = df.loc[df.index.year == year, :].copy(deep=True)\n",
    "    return result\n",
    "\n",
    "def split_train_test(X, y, col, sc=False):   # rows of x passed is last year (before last observation in the dataset)\n",
    "    '''\n",
    "    Used to split train and test set (year by year) + take care of correct Standardization and avoid data leakages\n",
    "    so that the scaler is refit only on the training data every time (and nothing of the test set is seen)\n",
    "    \n",
    "    If the splitting in done on the last year available for a dependent variable\n",
    "    we take up to last observation available (and go back by one entire year), that is we take care of missing values\n",
    "    '''\n",
    "    year_max = X.index.year.max()\n",
    "    if (col != \"logret_1week\") and (year_max == upp_bound[col].year):\n",
    "        low_test, upp_test = interm_bound[col], upp_bound[col]\n",
    "        X_test = X.loc[low_test:upp_test, :]  # Test set taken up to last available obs for each week lag\n",
    "        y_test = y.loc[low_test:upp_test, col].to_frame()\n",
    "        X_train = X.loc[:low_test, :]\n",
    "        y_train = y.loc[:low_test, col].to_frame()\n",
    "    else:\n",
    "        X_test = yr_map(X, year_max, lq=False)\n",
    "        y_test = y.loc[y.index.year == year_max, col].to_frame()\n",
    "        X_train = yr_map(X, year_max-1)\n",
    "        y_train = y.loc[y.index.year < year_max, col].to_frame()\n",
    "    if sc:\n",
    "        X_train, y_train, X_test, y_test = scale(sc, X_train, y_train, X_test, y_test)  # scaler function (below)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def scale(scaler, X_train, y_train, X_test=False, y_test=False):\n",
    "    '''\n",
    "    Used to scale appropriately on the basis of the scaler (dict) passed as parameter\n",
    "    it allows independent scaling for a selected subset of variables and prevents data leakages (only train set is seen)\n",
    "    Also only a set of data can be passed (to be completely standardized, used in PCA)\n",
    "    \n",
    "    scaler (dict): such as = {StandardScaler: [columns], MinMax: [columns]}\n",
    "                   if columns=0 applied to Y, otherwise to X\n",
    "    '''\n",
    "    regress = X_train.columns\n",
    "    for scal, variable in scaler.items():\n",
    "        if variable == 0:  # dependent variable\n",
    "            y_train = pd.DataFrame(data=scal.fit_transform(y_train), columns=y_train.columns)\n",
    "            if type(y_test)==pd.DataFrame:\n",
    "                y_test = pd.DataFrame(data=scal.transform(y_test), columns=y_test.columns)\n",
    "        else:\n",
    "            for ind in regress:\n",
    "                if ind in variable:\n",
    "                    X_train.loc[:, ind] = scal.fit_transform(X_train.loc[:, ind].to_numpy().reshape(-1, 1))\n",
    "                    if type(X_test)==pd.DataFrame:\n",
    "                        X_test.loc[:, ind] = scal.transform(X_test.loc[:, ind].to_numpy().reshape(-1, 1))\n",
    "    if type(X_test)==pd.DataFrame:\n",
    "        return X_train, y_train, X_test, y_test  # all are DataFrames\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1283997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transf():\n",
    "    '''\n",
    "    Implementation of log transformation for both Y and (all) X, !! dropping convex !! since extreme negative values (done on remaining columns)\n",
    "    It was done following some RFE cases in which convex were not selected\n",
    "    '''\n",
    "    X_log, Y_log = reinitialize()\n",
    "    X_log.drop(columns=[\"convexm2\", \"convexp2\"], inplace=True)  # dropping convex\n",
    "    X_min, Y_min = X_log.min().min(), Y_log.min().min()\n",
    "    e = 10**(-7)  # epsilon\n",
    "    scalar = Y_min if Y_min<X_min else X_min\n",
    "    X_log = np.log(X_log.add(-scalar + e))\n",
    "    Y_log = np.log(Y_log.add(-scalar + e))\n",
    "    print(\"Scalar added is: \", scalar + e)  # still need to add small amount and shift so that both X and Y are positive\n",
    "    return X_log, Y_log\n",
    "\n",
    "def log_transf_nopk(dep=True):  # whether also Y or not\n",
    "    '''\n",
    "    Log transformation excluding PK variables (so that convex is retained) and dependent if specified\n",
    "    dep: if True standardize also Y, otherwise not\n",
    "    '''\n",
    "    X, Y = reinitialize()\n",
    "    X_pk = X.loc[:, pricing_kernel]\n",
    "    X_macro = X.loc[:, except_kernel]\n",
    "    \n",
    "    e = 10**(-7)\n",
    "    X_min = X_macro.min().min()\n",
    "    Y_min = Y.min().min()\n",
    "    \n",
    "    if dep:\n",
    "        scalar = Y_min if Y_min<X_min else X_min\n",
    "        Y = np.log(Y.add(-scalar + e))\n",
    "    else: \n",
    "        scalar = X_min\n",
    "    X_macro = np.log(X_macro.add(-scalar + e))\n",
    "    X = pd.concat([X_pk, X_macro], axis=1)\n",
    "        \n",
    "    print(\"Scalar added is: \", -scalar + e) \n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ac2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(trans, X, predictors):\n",
    "    '''\n",
    "    Used for feature engineering on the regressors according to trans\n",
    "    Entire X (as dataframe) is passed since columns can be independently standardized according to the dictionary\n",
    "    trans (dict): similar to {PolynomialFeatures: [[new_columns], True], ....}  \n",
    "                  if last term in list True we concat otherwise we overwrite X\n",
    "    '''\n",
    "    for transf, [list_new, truth] in list(trans.items()):\n",
    "        X_transf = transf.fit_transform(X)\n",
    "        if truth: # if additional True we concat\n",
    "            X = pd.concat([X, pd.DataFrame(X_transf, columns=list_new, index=X.index)], axis=1)\n",
    "            if type(predictors)!=list:\n",
    "                predictors = predictors.to_list()\n",
    "            predictors.extend(list_new)\n",
    "        else:     # if false we overwrite\n",
    "            X = pd.DataFrame(data=X_transf, columns=list_new, index=X.index)\n",
    "            predictors = list_new\n",
    "    return X, predictors\n",
    "\n",
    "def rank_penalization(alpha):\n",
    "    '''\n",
    "    Used to print dependent with greater Penalization required (averaged over all alphas for each year)\n",
    "    alpha (dict): {'logret_1week': tot, ....}\n",
    "    '''\n",
    "    alpha = dict(sorted(alpha.items(), key=lambda x: x[1], reverse=True))\n",
    "    print(f\"Ranking of dependent with greater amount of penalization required (agg.):\")\n",
    "    for i, v in enumerate(alpha): \n",
    "        print(f\"{i}. {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88db030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR PLOTTING            \n",
    "\n",
    "def graph_comparison(scores, threshold=-8, light=False):\n",
    "    '''\n",
    "    Used to plot all scores, for each variable and each year, divided in 3 groups for visibility \n",
    "    scores that are >0 or <threshold are plotted (with different graphics and making sure they are visible)\n",
    "    \n",
    "    scores (dict): {'logret_1week': [score_1, score_2, ....], 'logret_2week': ....}\n",
    "    threshold (float/int): if scores are lower than this number they are visualized on the graph\n",
    "    \n",
    "    light (bool): using light=True if model is fit with light=True as well, which means that we are either plotting\n",
    "                  list(range(2004, 2016)) that is all years of evaluation or list(range(2004, 2016, 2)) skipping some years\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    years = [2004, 2006, 2008, 2010, 2012, 2014] if light else list(range(2004, 2016))\n",
    "    positions = [0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    to_plot = {x: [] for x in Y.columns}\n",
    "    distance = positions.copy()\n",
    "    tick_marks = np.arange(len(years))\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(28, 20))\n",
    "    \n",
    "    for key, value in scores.items():\n",
    "        delay = int(re.search(r\"\\d+\", key).group(0))\n",
    "        if delay < 6:                        # 1, 2, 3, 4, 5\n",
    "            ax = ax1\n",
    "        elif delay == 6:\n",
    "            ax = ax2\n",
    "            distance = positions.copy()\n",
    "        elif (delay > 6) and (delay < 13):    # 6, 7, 8, 9, 12\n",
    "            ax = ax2\n",
    "        elif delay == 24:\n",
    "            ax = ax3\n",
    "            distance = positions.copy()\n",
    "        else:                              # 24, 36, 52, 78, 104\n",
    "            ax = ax3\n",
    "        prop = distance.pop(0)\n",
    "        p = ax.plot(value, label=str(key).split(\"_\")[1], linewidth=2)\n",
    "        to_plot[key].extend([ax, prop, p[0].get_color()])\n",
    "        for i, v in enumerate(value):\n",
    "            if (v < threshold) or (v>0):   \n",
    "                to_plot[key].append(i)\n",
    "        ax.legend(loc='upper right', fontsize=14)\n",
    "        ax.set_xticks(tick_marks)\n",
    "        ax.set_xticklabels(years)\n",
    "        ax.set_xlabel('Year of training set', fontsize=16)\n",
    "        ax.set_ylabel(r'$R^2$', fontsize=18)\n",
    "        ax.set_title('Performance of model', fontsize=18)\n",
    "    \n",
    "    for col, lst in to_plot.items():  # scores are plotted in order of labels at different propotion of the graph's height, to make them visible\n",
    "        y_bound = lst[0].get_ylim()\n",
    "        y = lst[1]*(y_bound[1]-y_bound[0]) + y_bound[0]\n",
    "        for yr in lst[3:]:\n",
    "            value = scores[col][int(yr)]\n",
    "            w = \"extra bold\" if value>0 else \"ultralight\"\n",
    "            f1 = \"normal\" if value>0 else \"italic\"\n",
    "            f2 = \"large\" if value>0 else \"medium\"\n",
    "            lst[0].text(yr, y, \"{:.3f}%\".format(value), c=lst[2],\n",
    "                        weight=w, ha=\"center\", fontstyle=f1, fontsize=\"large\")  #.format(value[i])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddff7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_aggregate(aggregate=False, scores=False):\n",
    "    '''\n",
    "    Used to store in a dataframe and visualize 3 columns: - Agg Scores (avg), - Two last years (individual values)\n",
    "    The dataframe is sorted according to - Agg Scores\n",
    "    \n",
    "    aggregate (dict): {'logret_1week': avg_scores, ...}\n",
    "    scores (dict): {'logret_1week': [score_1, score_2, ...], ...}\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    sor = aggregate if type(aggregate)==dict else scores\n",
    "    d = sorted(sor, key=sor.get, reverse=True)\n",
    "    store = {'Ranked models': [i for i in d]}\n",
    "    if type(aggregate)==dict:\n",
    "        store.update({'Agg Scores': [aggregate[i] for i in d]})\n",
    "    if type(aggregate)==dict and type(scores)==dict:\n",
    "        store.update({'': ['' for i in d]})\n",
    "    if type(scores)==dict:\n",
    "        try:\n",
    "            store.update({'One to last': [scores[i][-2] for i in d]})\n",
    "            store.update({'Last year': [scores[i][-1] for i in d]})\n",
    "        except:\n",
    "            store.update({'Last year': [scores[i] for i in d]})\n",
    "    visual = pd.DataFrame(store)\n",
    "    return visual  \n",
    "\n",
    "\n",
    "def print_aggregate(aggregate):\n",
    "    print(\"RANKING WITH AVERAGE\")\n",
    "    for k, i in enumerate(sorted(aggregate, key=aggregate.get, reverse=True)):\n",
    "        print(f\"{k}. Score for {i}: {aggregate[i]}\")\n",
    "        \n",
    "        \n",
    "def sort_coefficient(coeff):\n",
    "    '''\n",
    "    Used at the beginning to manually select stronger coefficients and run independent regressions\n",
    "    Only last year coefficients are stored through train_recursive\n",
    "    coeff (dict)\n",
    "    \n",
    "    '''\n",
    "    predictors = list(X.columns)\n",
    "    ranked_coeff = {y: 0 for y in Y.columns}\n",
    "    for time_span, coef in coeff.items():\n",
    "        idx = np.argsort(coef, axis=0)[::-1].flatten().tolist()\n",
    "        ranked_predictors = [predictors[i] for i in idx]\n",
    "        ranked_coeff[time_span] = ranked_predictors\n",
    "    return pd.DataFrame(data = ranked_coeff)\n",
    "\n",
    "\n",
    "def visualize_selected(selected, year=False, light=False, to_print=10):\n",
    "    '''\n",
    "    Used to visualize selected variables for each dependent variable\n",
    "    selected (dict): {'logret_1week': [[select1_y1, select2_y1, ...], [select1_y2, select2_y2, ...], [],..], 'logret_2week': ...}\n",
    "    \n",
    "    year=int       (year from 2004 to 2015) -> we can visualize features selected for that year\n",
    "    year=False      we visualize last year avaiable for each variable\n",
    "    year=None       visualize for each dep most common selected variables among all years, \n",
    "                    sorted by appearence, and with absolute frequencies between ()\n",
    "                    \n",
    "    light (bool):    set to True if model is fit with light=True (to make sure invalid years cannot be asked for)\n",
    "    \n",
    "    to_print (int):  select how much of the ranking to print (for each dependent)\n",
    "    \n",
    "    '''\n",
    "    prox = {}\n",
    "    if year==False:\n",
    "        prox = {k: v[-1] for k, v in selected.items()}\n",
    "        prox = dict(sorted(prox.items(), key=lambda x: int(re.search(r\"\\d+\", x[0]).group(0))))\n",
    "    elif year==None:\n",
    "        for dep, lst in selected.items():\n",
    "            c = Counter()\n",
    "            for dframe in lst:\n",
    "                c.update(dframe[dep].tolist())\n",
    "            common = [str(f) + \" (\" + str(s) + \")\" for f, s in c.most_common(to_print)]   \n",
    "            prox[dep] = pd.DataFrame({dep: common})\n",
    "    else:\n",
    "        years = [2004, 2006, 2008, 2010, 2012, 2014] if light else list(range(2004, 2016))\n",
    "        try:\n",
    "            idx = years.index(year)\n",
    "        except:\n",
    "            print('Not valid year')\n",
    "        for k, v in selected.items():\n",
    "            try:\n",
    "                prox[k] = v[idx]\n",
    "            except:\n",
    "                continue\n",
    "        #prox = {k: v[idx] for k, v in selected.items()}\n",
    "        prox = dict(sorted(prox.items(), key=lambda x: int(re.search(r\"\\d+\", x[0]).group(0))))\n",
    "    c = pd.DataFrame()\n",
    "    for variable, df in prox.items():\n",
    "        c = pd.concat([c, df], axis=1)\n",
    "    c.fillna(value=\"\", inplace=True)\n",
    "    return c\n",
    "\n",
    "def plot_selected(selected, dependent):\n",
    "    '''\n",
    "    To plot how number of features selected change across the years (not used much)\n",
    "    '''\n",
    "    length = []\n",
    "    for df in selected[dependent]:\n",
    "        length.append(len(df[dependent].tolist()))\n",
    "    tick_marks = np.arange(len(length))\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "    ax.plot(np.array(length), linewidth=2)\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(list(range(2004, 2004+len(length))))\n",
    "    ax.set_xlabel('Year of training set', fontsize=16)\n",
    "    ax.set_ylabel('Number of features selected', fontsize=18)\n",
    "    ax.set_title(f'Evolution of features selected for {dependent}', fontsize=18)  \n",
    "    plt.show()\n",
    "    \n",
    "def compare_preds(Y, preds, col, y=2012, light=False):\n",
    "    '''\n",
    "    Used to plot the real Y values and the predicted values for a particular year and a particular dependent variable\n",
    "    \n",
    "    preds (dict)   as returned by all methods implemented (store all predictions for all years)\n",
    "    col (str):     name of wanted columns (such as 'logret_1week')\n",
    "    y (int):       wanted year\n",
    "    light (bool):  to be set to true if model is fit with light\n",
    "    \n",
    "    '''\n",
    "    lig = [2004, 2006, 2008, 2010, 2012, int(upp_bound[col].year)]\n",
    "    if (light==True) and (y not in lig):\n",
    "        return\n",
    "    if y > upp_bound[col].year or y < 2004:\n",
    "        return\n",
    "    elif y == upp_bound[col].year:\n",
    "        low_test, upp_test = interm_bound[col], upp_bound[col]\n",
    "        real = Y.loc[low_test:upp_test, col]\n",
    "    else:\n",
    "        real = Y.loc[Y.index.year==y, col]\n",
    "    if light:\n",
    "        pred = preds[col][lig.index(y)]\n",
    "    else:\n",
    "        pred = preds[col][y-2004]\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    plt.title('Predictions of '+ str(col) + ' for year ' + str(y))\n",
    "    plt.plot(real.index, real, linewidth=2, label='Real')\n",
    "    plt.plot(real.index, pred, label='Predicted')\n",
    "    plt.legend(fontsize=\"medium\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8caca035",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def train_recursive(model, X, y, column=False, scal=False, score=False, ravel_=False, light=False, tr=False):   \n",
    "    '''\n",
    "    Used to train recursively a given model over all the years (up to each available year and observation) for each lagged week\n",
    "    uses a specific model already runed\n",
    "    \n",
    "    model : sklearn estimator\n",
    "    X, y : entire dataset as output by reinitialize\n",
    "    scal (dict): calls the preceding functions to standardize the data, such as {StandardScaler: [columns], MinMax: [columns]}\n",
    "    \n",
    "    score (bool): !!!! if True demeaned R2 is used\n",
    "    light (bool): !!! whether to compute for all years or skipping some\n",
    "    tr (bool): to specifies if it is a tree or not\n",
    "    columns (str): if computing for one specific column or for all recursively\n",
    "    \n",
    "    '''\n",
    "    if not column:\n",
    "        scores = {x: [] for x in y.columns}  \n",
    "        aggregate = {x: 0 for x in y.columns}\n",
    "        predic = {x: [] for x in y.columns}\n",
    "        dependent = y.columns\n",
    "        start_time=timer(None)\n",
    "        if tr==False:\n",
    "            coeff = {x: 0 for x in y.columns}\n",
    "    else: \n",
    "        scores = {column: []}  \n",
    "        aggregate = {column: 0}\n",
    "        predic = {column: []}\n",
    "        dependent = [column]\n",
    "        if tr==False:\n",
    "            coeff = {column: 0}\n",
    "        y = pd.DataFrame(data=y, columns=[column], index=X.index)    \n",
    "    span = range(2004, X.index.year.max()+1)\n",
    "    if (light==True and column==True):\n",
    "        span = [2004, 2006, 2008, 2010, 2012, int(upp_bound[column].year)]\n",
    "    for year in span: # start with test set 2003-2004\n",
    "        for time_span in dependent:\n",
    "            if year > upp_bound[time_span].year:  # up to each available year\n",
    "                continue\n",
    "            X_train, y_train, X_test, y_test = split_train_test(yr_map(X, year), yr_map(y, year), col=time_span, sc=scal)\n",
    "            trained = model.fit(X_train.values, y_train.values.ravel()) if ravel_==True else model.fit(X_train.values, y_train.values)\n",
    "            preds = trained.predict(X_test.values)\n",
    "            predic[time_span].append(preds) # storing predictions to plot\n",
    "            if score:   # use demeaned score\n",
    "                scores[time_span].append(impl_r2(y_test, preds))  # scores contains all scores in dimension n.years*lagged weeks\n",
    "            else:\n",
    "                scores[time_span].append(trained.score(X_test.values, y_test.values))\n",
    "            if tr==False: # take coefficient only of the largest training set (max year=max available year) and not for trees\n",
    "                if (year==2013) and (time_span==\"logret_104week\"):\n",
    "                    coeff[time_span] = trained.coef_.reshape(-1, 1)  \n",
    "                if (year==2014) and (time_span in [\"logret_78week\", \"logret_52week\", \"logret_36week\"]):\n",
    "                    coeff[time_span] = trained.coef_.reshape(-1, 1)\n",
    "                if (year==2015) and (time_span not in [\"logret_104week\", \"logret_78week\", \"logret_52week\", \"logret_36week\"]):\n",
    "                    coeff[time_span] = trained.coef_.reshape(-1, 1)\n",
    "    for key, value in scores.items():\n",
    "        aggregate[key] = np.array(value).mean()\n",
    "    if not column:\n",
    "        timer('recursive training', start_time)\n",
    "    if tr==False:\n",
    "        return aggregate, scores, coeff, predic\n",
    "    return aggregate, scores, predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf8e3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_selection_full(estimat, X, Y, col=False, scaler=False, score=False, min_feat=1, light_=False, tree=False, ravel=False):\n",
    "    '''\n",
    "    Function to implement RFE recursively for each year for any given model, taking care of all scores, predictions, selected variables...\n",
    "    using TimeSeriesSplit as a validation technique\n",
    "    \n",
    "    estimat is sklearn estimator\n",
    "    scaler (dict) as above\n",
    "    score (bool): if True using demeaned R2\n",
    "    \n",
    "    light_ (bool): if computing for all years or a subset of years\n",
    "    '''\n",
    "    if not col:\n",
    "        aggregate = {x: 0 for x in Y.columns}   # mean across years for each dependent lagged week\n",
    "        selected = {x: [] for x in Y.columns}  # to store variables selected\n",
    "        scores = {x: [] for x in Y.columns}\n",
    "        preds = {x: [] for x in Y.columns}\n",
    "        dep = Y.columns\n",
    "        start_time=timer(None)\n",
    "    else:\n",
    "        scores = {col: []}  \n",
    "        aggregate = {col: 0}\n",
    "        selected = {col: []}\n",
    "        preds = {col: []}\n",
    "        dep = [col]\n",
    "        Y = pd.DataFrame(data=Y, columns=[col], index=X.index)\n",
    "        \n",
    "    span = list(range(2004, X.index.year.max()+1))\n",
    "    if light_==True:\n",
    "        span = list(range(2004, 2013, 2)) # light subset of available years\n",
    "    predictors = X.columns\n",
    "    year_min, year_max = X.index.year.min(), X.index.year.max()\n",
    "    \n",
    "    for dependent in tqdm(dep): \n",
    "        for year in span: # start with test set 2004\n",
    "            if year > upp_bound[dependent].year:  # up to each available year\n",
    "                continue\n",
    "            if (light_==True) and (year==2004):\n",
    "                span.append(int(upp_bound[dependent].year))\n",
    "            X_train, y_train, X_test, y_test = split_train_test(yr_map(X, year), yr_map(Y, year), col=dependent, sc=scaler)\n",
    "                \n",
    "            generator = TimeSeriesSplit(n_splits = 3)  \n",
    "            x = impl_score if score else 'r2'\n",
    "            mod = clone(estimat) if tree not in [True, None] else PermutationImportance(estimat, scoring=x, n_iter=5, cv=TimeSeriesSplit(n_splits = 3))  # Permutation with cv (also) shows importance of features for generalization\n",
    "\n",
    "            # Feature Selection \n",
    "            rfe = RFECV(estimator=mod, cv=generator, min_features_to_select=min_feat, scoring=x)  \n",
    "            trained = rfe.fit(X_train.values, y_train.values.reshape(-1,)) if ravel==True else rfe.fit(X_train.values, y_train.values)\n",
    "\n",
    "            # storing\n",
    "            select_regress = np.array(predictors)[trained.get_support()].tolist()\n",
    "            selected[dependent].append(pd.DataFrame({dependent: select_regress})) # storing\n",
    "            \n",
    "            pred = trained.predict(X_test.values)\n",
    "            preds[dependent].append(pred) # storing predictions to plot\n",
    "            \n",
    "            sc = impl_r2(y_test, pred) if score else trained.score(X_test.values, y_test.values)\n",
    "            scores[dependent].append(sc)  \n",
    "            \n",
    "        aggregate[dependent] = np.array(scores[dependent]).mean()\n",
    "        if light_==True:\n",
    "            span.pop(-1)   \n",
    "            \n",
    "    if not col:\n",
    "        timer('feature selection', start_time)\n",
    "\n",
    "    return selected, scores, aggregate, preds\n",
    "\n",
    "#print(f\"Out of {rfe.n_features_in_}, {rfe.n_features_} were selected for {dependent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2c723a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lasso(X, Y, col=False, scaler=False, light_=False, scor=False, thresh_prop=1.2):\n",
    "    '''\n",
    "    LassoCV implementation for feature engineering. Taking take that, if no variable is selected, SelectFromModel\n",
    "    is used to raise progressively the threshold until few features are indeed selected\n",
    "    \n",
    "    light_ see above\n",
    "    scor: seems that LassoCV uses R2 by default but if scor==True the score appended (and plotted) are the Demeaned R2\n",
    "    \n",
    "    thresh_prop: threshold used in a small loop inside to ensure that some variables are selected (the higher, the quicker)\n",
    "    '''\n",
    "    if not col:\n",
    "        aggregate = {x: 0 for x in Y.columns}   # mean across years for each dependent lagged week\n",
    "        selected = {x: [] for x in Y.columns}  # to store variables selected\n",
    "        scores = {x: [] for x in Y.columns}\n",
    "        preds = {x: [] for x in Y.columns}\n",
    "        alpha = {x: [] for x in Y.columns}\n",
    "        dep = Y.columns\n",
    "        start_time=timer(None)\n",
    "    else:\n",
    "        scores = {col: []}  \n",
    "        aggregate = {col: 0}\n",
    "        selected = {col: []}\n",
    "        preds = {col: []}\n",
    "        alpha = {col: []}\n",
    "        dep = [col]\n",
    "        Y = pd.DataFrame(data=Y, columns=[col], index=X.index)\n",
    "    \n",
    "    span = list(range(2004, X.index.year.max()+1))\n",
    "    if light_==True:\n",
    "        span = list(range(2004, 2013, 2))\n",
    "        \n",
    "    predictors = X.columns\n",
    "    year_min, year_max = X.index.year.min(), X.index.year.max()\n",
    "  \n",
    "    for dependent in tqdm(dep):\n",
    "        for year in span: # start with test set 2003-2004\n",
    "            if year > upp_bound[dependent].year:  # up to each available year\n",
    "                continue\n",
    "            if (light_==True) and (year==2004):\n",
    "                span.append(int(upp_bound[dependent].year))\n",
    "            X_train, y_train, X_test, y_test = split_train_test(yr_map(X, year), yr_map(Y, year), col=dependent, sc=scaler)\n",
    "            \n",
    "            generator = TimeSeriesSplit(n_splits = 5)\n",
    "            # fitting\n",
    "            lasso = LassoCV(cv=generator, selection='random', max_iter=100000, eps=1e-3, tol=5e-4)   # tol=0.0005\n",
    "            trained = lasso.fit(X_train, y_train)  #trained = lasso.fit(X_train, y_train.values.ravel())\n",
    "            \n",
    "            # storing\n",
    "            alpha_ = trained.alpha_\n",
    "            alpha[dependent].append(alpha_)\n",
    "            select_regress = np.array(predictors)[np.nonzero(trained.coef_)[0]].tolist()\n",
    "\n",
    "            if len(select_regress) < 1:   # to make sure strongest variables selected even if initially discarded\n",
    "                thresh = \"median\"\n",
    "                #print(\"IN LOOP\")\n",
    "                while len(select_regress) not in [1, 2, 3]:\n",
    "                    sfm = SelectFromModel(LinearRegression(), threshold=thresh).fit(X_train, y_train)\n",
    "                    select_regress = np.array(predictors)[sfm.get_support()].tolist()\n",
    "                    #print(f\"selected: {len(select_regress)}\")\n",
    "                    thresh = sfm.threshold_ * thresh_prop\n",
    "                    if len(select_regress)==0:\n",
    "                        #print(\"STUCK\")\n",
    "                        thresh = \"mean\"\n",
    "                #print(\"EXIT LOOP\")\n",
    "                X_test = sfm.transform(X_test)\n",
    "                trained = sfm.estimator_.fit(sfm.transform(X_train), y_train)\n",
    "\n",
    "            selected[dependent].append(pd.DataFrame({dependent: select_regress})) # storing\n",
    "        \n",
    "            pred = trained.predict(X_test)  #.values\n",
    "            preds[dependent].append(pred) # storing predictions to plot\n",
    "            \n",
    "            sc = impl_r2(y_test, pred) if scor else trained.score(X_test, y_test) # trained.score(X_test, y_test.values)\n",
    "            scores[dependent].append(sc)  \n",
    "        \n",
    "        aggregate[dependent] = np.array(scores[dependent]).mean()\n",
    "        if light_==True:\n",
    "            span.pop(-1)\n",
    "            \n",
    "    alpha = {k: np.array(v).mean() for k, v in alpha.items()}\n",
    "    rank_penalization(alpha)\n",
    "    timer('lasso', start_time)\n",
    "    \n",
    "    return selected, scores, aggregate, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "809226bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search(X, Y, model, params_light, params_hard, scal_=False, sco=False, selection=False, _light_=False, tree_=False):\n",
    "    '''\n",
    "    Used for hyper-parameter tuning given a list\n",
    "    \n",
    "    (only if selection == True)\n",
    "                1) Iniziatially RandomizedSearchCV is used on data up to year 2004 (the first training set)\n",
    "                to (lightly) select appropriate hyperparameters and avoid conditioning feature selection\n",
    "                2) Then Feature selection is performed upon this (lightly) optimized model\n",
    "    \n",
    "    (both if selection==True or False)\n",
    "                Eventually GridSearchCV is fitted to squeeze the model predictability, for each year and dependent variable\n",
    "    \n",
    "    params_light (dict): list of hyperparameters to be (lightly) selected using 2001-2003 as test set\n",
    "    params_hard (dict): full list of hyperparameters to be evaluated once features are selected\n",
    "    \n",
    "    scal_ (dict): dictionary with scalers (see above)\n",
    "    selection (bool): determines whether feature selection is performed or not\n",
    "    \n",
    "    _light_ (bool): whether to use all available years or the subset (2004, 2006, 2008...)\n",
    "    \n",
    "    tree_: if None a single tree is used (say Decision Tree) so node_count and depth of fitted tree is stored\n",
    "            if True/False is an ensemble Algo and these parameters are not stored (as we have multiple trees)\n",
    "    '''\n",
    "    \n",
    "    agg = {x: 0 for x in Y.columns} \n",
    "    selected = {x: [] for x in Y.columns}\n",
    "    scores = {x: [] for x in Y.columns}\n",
    "    preds = {x: [] for x in Y.columns}\n",
    "    dep = Y.columns\n",
    "    params_grid = {x: [] for x in Y.columns}\n",
    "    params_tree = {x: [] for x in Y.columns}\n",
    "    \n",
    "    predictors = X.columns\n",
    "    year_min, year_max = X.index.year.min(), X.index.year.max()  \n",
    "    x = impl_score if sco else 'r2'\n",
    "    start_time=timer(None)  # timer start\n",
    "    \n",
    "    span = list(range(2004, X.index.year.max()+1))\n",
    "    if _light_==True:\n",
    "        span = list(range(2004, 2013, 2))\n",
    "    \n",
    "    for dependent in tqdm(Y.columns):        \n",
    "        for year in span: # start with test set 2003-2004\n",
    "            if year > upp_bound[dependent].year:  # up to each available year\n",
    "                continue\n",
    "            if (_light_==True) and (year==2004):\n",
    "                span.append(int(upp_bound[dependent].year))\n",
    "            if selection:\n",
    "                if year==2004:\n",
    "                    X_tr, Y_tr, X_te, Y_te = split_train_test(yr_map(X, year), yr_map(Y, year), col=dependent, sc=scal_)\n",
    "                    _gen = TimeSeriesSplit(n_splits = 3) \n",
    "                    first = RandomizedSearchCV(estimator=model, cv=_gen, param_distributions=params_light, n_iter=150, scoring=x, n_jobs=-1, verbose=0)\n",
    "                    trained = first.fit(X_tr, Y_tr.values.ravel())\n",
    "                    first_mod = trained.best_estimator_ # clone(model).set_params(**lax.best_params_)\n",
    "                if year != 2004:\n",
    "                    X_tr, Y_tr, X_te, Y_te = split_train_test(yr_map(X, year), yr_map(Y, year), col=dependent, sc=scal_)\n",
    "                    \n",
    "                gen_ = TimeSeriesSplit(n_splits = 5)  \n",
    "                mod = first_mod if tree_ not in [True, None] else PermutationImportance(first_mod, scoring=x, n_iter=3, cv=TimeSeriesSplit(n_splits = 5))  # Permutation with cv (also) shows importance of features for generalization\n",
    "                \n",
    "                # Feature Selection \n",
    "                rfe = RFECV(estimator = mod, cv=gen_, min_features_to_select=1, scoring=x)  \n",
    "                try:\n",
    "                    trained = rfe.fit(X_tr, Y_tr.values)      # if ravel==True else rfe.fit(X_tr.values, Y_tr.values) .values.reshape(-1,)\n",
    "                    \n",
    "                    # storing\n",
    "                    select_regress = np.array(predictors)[trained.get_support()].tolist()\n",
    "                    selected[dependent].append(pd.DataFrame({dependent: select_regress})) # storing        \n",
    "\n",
    "                    X_tr = pd.DataFrame(data=rfe.transform(X_tr), columns=select_regress, index=X_tr.index)\n",
    "                    X_te = pd.DataFrame(data=rfe.transform(X_te), columns=select_regress, index=X_te.index)\n",
    "                except ValueError:\n",
    "                    print(f\"RFE for {dependent} year {year} did not converge\")\n",
    "                    selected[dependent].append(pd.DataFrame({dependent: np.array(predictors).tolist()}))\n",
    "                    X_tr, Y_tr, X_te, Y_te = split_train_test(yr_map(X, year), yr_map(Y, year), col=dependent, sc=scal_)\n",
    "            else:\n",
    "                X_tr, Y_tr, X_te, Y_te = split_train_test(yr_map(X, year), yr_map(Y, year), col=dependent, sc=scal_)\n",
    "            \n",
    "            generator = TimeSeriesSplit(n_splits = (year - 2004 + 2)) # year 2004 starts with n_splits=2 then +1 every yea\n",
    "            grid = GridSearchCV(estimator=model, cv=generator, param_grid=params_hard, scoring=x, n_jobs=-1, verbose=0, refit=True)\n",
    "            trained = grid.fit(X_tr, Y_tr.values.ravel())\n",
    "            params_grid[dependent].append(grid.best_params_)\n",
    "            \n",
    "            pred = trained.predict(X_te)\n",
    "            preds[dependent].append(pred) # storing predictions to plot\n",
    "            \n",
    "            sc = impl_r2(y_test, pred) if sco else grid.score(X_te, Y_te.values)\n",
    "            scores[dependent].append(sc) \n",
    "            \n",
    "            if tree_==None:\n",
    "                tr = trained.best_estimator_.tree_\n",
    "                params_tree[dependent].append([tr.node_count, tr.max_depth])            \n",
    "            \n",
    "        agg[dependent] = np.array(scores[dependent]).mean()\n",
    "        if _light_==True:\n",
    "            span.pop(-1)     \n",
    "            \n",
    "    timer('grid search', start_time) # timer\n",
    "    print(\"\")\n",
    "    \n",
    "    if selection: \n",
    "        if tree_==None:\n",
    "            return selected, agg, scores, [params_grid, params_tree], preds   # preds only if selection\n",
    "        return selected, agg, scores, params_grid, preds\n",
    "    if tree_==None:\n",
    "        return agg, scores, [params_grid, params_tree], preds\n",
    "    return agg, scores, params_grid, preds\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e99db74c-89d1-4e9d-84a4-d5743288be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param(params, params_tree=False):\n",
    "    '''\n",
    "    Function used to plot the set of parameters chosen by the (hard) GridSearch\n",
    "    \n",
    "    if params_tree is a dict: print also most common n.nodes and tree_depth for the fitted tree (for each dependent)\n",
    "    '''\n",
    "    for i, (dep, param) in enumerate(params.items()):\n",
    "        final = []\n",
    "        store = [[] for _ in range(len(param[0]))]\n",
    "        \n",
    "        if params_tree:\n",
    "                node_count = [params_tree[dep][x][0] for x in range(len(params_tree[dep]))]\n",
    "                depth_count = [params_tree[dep][x][1] for x in range(len(params_tree[dep]))]\n",
    "                node_mean = np.array(node_count).mean(dtype=int)\n",
    "                depth_mean = np.array(depth_count).mean(dtype=int)\n",
    "                \n",
    "        for p_year in param:\n",
    "            for i, (p, value) in enumerate(p_year.items()):\n",
    "                store[i].append(p + \": \" + str(value))\n",
    "                \n",
    "        for var in store:\n",
    "            c = Counter(var)\n",
    "            final.append(c.most_common(1)[0][0])\n",
    "        \n",
    "        a = f\"\\t \\t \\t \\t Fitted model's avg. node counts: {node_mean} \\t \\t avg. depth count = {depth_mean}\" if params_tree else \"\"\n",
    "        print(f\"\\nDependent {dep}:\" + a)\n",
    "        for i in final:\n",
    "            print(f\"\\t \\t Most common {i}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7a989",
   "metadata": {},
   "source": [
    "### Spline transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3155c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_spline(columns, X, knots=3, degree=2):  # columns = ['var', 'ra']\n",
    "    '''\n",
    "    Function to find generated splines from a set of columns (to standardize them)\n",
    "    '''\n",
    "    f = []\n",
    "    for group in columns:\n",
    "        for col in group:\n",
    "            index = X.columns.to_list().index(col)\n",
    "            low = index*(knots+degree-1)+1\n",
    "            names = [str(i) for i in range(low, low + (knots+degree-1))]\n",
    "            f += names\n",
    "    return f\n",
    "\n",
    "def s_spline(group, X, knots=3, degree=2, vis=False):            # group = [1, 2, 3, 4]\n",
    "    '''\n",
    "    Inverse function of above\n",
    "    '''\n",
    "    for spline in group:\n",
    "        index = int((int(spline)-1)/(knots+degree-1))   # inverse of spline creation to find original linear regressor\n",
    "        col = X.columns.to_list()[index]\n",
    "        if vis:\n",
    "            print(f\"{spline} is a spline transformation of {col}\")\n",
    "    return\n",
    "    \n",
    "def print_common(store, X, to_print=5, kn=3, deg=2):  # store is database of selected regressors, X is common X not standardized\n",
    "    '''\n",
    "    Function used to find the most common splines in the Dataset of selected variables ( dependent on to_print (int) )\n",
    "    and print their origin (i.e. which dependent variable they are the Spline transformation of)\n",
    "    '''\n",
    "    e = Counter()\n",
    "    for dep, lst in store.items():\n",
    "        c = Counter()\n",
    "        d = Counter()\n",
    "        for dframe in lst:\n",
    "            c.update(dframe[dep].tolist())\n",
    "        for var, freq in c.items():\n",
    "            try:\n",
    "                x = int(var)\n",
    "                d.update({var: freq})\n",
    "            except:\n",
    "                continue\n",
    "        c = {f:s for (f, s) in d.most_common(15)}\n",
    "        e.update(c)\n",
    "    fin = [a for (a, l) in e.most_common(to_print)]\n",
    "    s_spline(fin, X, kn, deg, vis=True)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e78044",
   "metadata": {},
   "source": [
    "### Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2192623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_int(to_find, col_names):  # to_find = ['var', 'ra'], col_names=above\n",
    "    '''\n",
    "    Used to find all interaction generated from a given set of columns\n",
    "    '''\n",
    "    f = set()\n",
    "    for group in to_find:\n",
    "        for col in group:\n",
    "            names = [inter for inter in col_names if re.search(col, inter)]\n",
    "            f.update(names)\n",
    "    return list(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4d106",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c2414d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_component(comp, columns):\n",
    "    '''\n",
    "    Used to explain the composition (in terms of % of direction) of the Principal Component generated by the PCA transformation\n",
    "    derived from the definition of Principal Component and the way they are derived\n",
    "    '''\n",
    "    a = [(np.round_((comp[i]**2)*100, decimals=1), columns[i]) for i in range(len(comp))]\n",
    "    a.sort(key = lambda x: x[0], reverse=True)\n",
    "    \n",
    "    n, i = 0, 0\n",
    "    while n<70:\n",
    "        print(f\"{a[i][0]} % of component's direction: {a[i][1]}\")\n",
    "        n += a[i][0]\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "def print_pca(store, pca_var, cols, to_print=5):  # store is database of selected regressors, X is common X not standardized\n",
    "    '''\n",
    "    Similar to above but for PCA, print most common PComponents selected out of the store with all\n",
    "    the selections and their composition in terms of % of original regressors\n",
    "    '''\n",
    "    # print pca from store (descending order for frequency)\n",
    "    e = Counter()\n",
    "    for dep, lst in store.items():\n",
    "        c = Counter()\n",
    "        d = Counter()\n",
    "        for dframe in lst:\n",
    "            c.update(dframe[dep].tolist())\n",
    "        for var, freq in c.items():\n",
    "            if re.search(r'\\bPC', var): \n",
    "                d.update({var: freq})\n",
    "        c = {f:s for (f, s) in d.most_common(15)}\n",
    "        e.update(c)\n",
    "    fin = [int(re.search(r'\\d+' ,a).group(0)) for (a, l) in e.most_common(to_print)]\n",
    "    for i in fin:\n",
    "        print(\"PC\" + str(i))\n",
    "        explain_component(pca_var.components_[i-1], columns=cols)\n",
    "        print(\"\")\n",
    "    return\n",
    "\n",
    "\n",
    "def fit_pca(X, col=False, perc=0.9): \n",
    "    '''\n",
    "    Used to fit PCA to a subset of columns (and Standardizing them first to mean 0 and variance 1)\n",
    "    keeping the remaining set of regressors (not inside 'col') linear\n",
    "    \n",
    "    col (list): list of columns' names to be transformed\n",
    "    perc (float):  % of total variance of selected columns to explain\n",
    "    '''\n",
    "    pca = PCA(n_components=perc, svd_solver='full')\n",
    "    if col:\n",
    "        oth = [X.columns.to_list()[i] for i in range(X.shape[1]) if X.columns.to_list()[i] not in col]\n",
    "        X_sel = pd.DataFrame(data=StandardScaler().fit_transform(X.loc[:, col]), columns=col)\n",
    "        X_oth = X.loc[:, oth]\n",
    "        pca.fit(X_sel)\n",
    "        pc_names = ['PC' + str(i+1) for i in range(pca.n_components_)]\n",
    "        X_pca = pd.DataFrame(data = pca.transform(X_sel), columns=pc_names, index=X.index)\n",
    "        X = pd.concat([X_pca, X_oth], axis=1)\n",
    "    else:\n",
    "        col = X.columns.to_list()\n",
    "        X = pd.DataFrame(data=StandardScaler().fit_transform(X), columns=col, index=X.index)\n",
    "        pca.fit(X)\n",
    "        pc_names = ['PC' + str(i+1) for i in range(pca.n_components_)]\n",
    "        X = pd.DataFrame(data = pca.transform(X), columns=pc_names, index=X.index)\n",
    "    print(f\"{pca.n_components_} components explain {perc: .0%} of the variance for the selected columns {col} \\n\")\n",
    "    for i in range(pca.n_components_):\n",
    "        print(f\"The {i+1} explains {pca.explained_variance_ratio_[i]: .1%}%\")\n",
    "    return X, pca\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46648b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b20636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20799f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae989015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693eebe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd4d92b4",
   "metadata": {},
   "source": [
    "#### Additional Code saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701df8d",
   "metadata": {},
   "source": [
    "X, Y = reinitialize()\n",
    "X_tr, Y_tr, X_te, Y_te = split_train_test(yr_map(X, 2006), yr_map(Y, 2006), col='logret_1week')\n",
    "X_tr.index\n",
    "\n",
    "print(X_tr.index[0])\n",
    "print(X_tr.index[-1])\n",
    "\n",
    "generator = TimeSeriesSplit(n_splits = 3)\n",
    "print(X_tr.shape)\n",
    "idx = X_tr.index\n",
    "print('Index PRE', idx[0], idx[-1])\n",
    "for train_index, test_index in generator.split(X_tr):\n",
    "    print(\"TRAIN:\", train_index, \"\\nTEST:\", test_index)\n",
    "    X_train, X_test = X_tr.iloc[train_index, :], X_tr.iloc[test_index, :]\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    idx = X_test.index\n",
    "    print('Index POST', idx[0], idx[-1])\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f4425b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_light(estimat, X, Y, col=False, scaler=False, score=False, min_feat=1):  #score True if using demeaned\n",
    "    if not col:\n",
    "        aggregate = {x: 0 for x in Y.columns}   # mean across years for each dependent lagged week\n",
    "        selected = {x: 0 for x in Y.columns}  # to store variables selected\n",
    "        scores = {x: [] for x in Y.columns}\n",
    "        dep = Y.columns\n",
    "        start_time=timer(None)\n",
    "    else:\n",
    "        scores = {col: []}  \n",
    "        aggregate = {col: 0}\n",
    "        selected = {x: 0 for x in Y.columns}\n",
    "        dep = [col]\n",
    "        Y = pd.DataFrame(data=Y, columns=[col], index=X.index)\n",
    "    predictors = X.columns\n",
    "    year_min, year_max = X.index.year.min(), X.index.year.max()\n",
    "    for dependent in dep: \n",
    "        y_max = upp_bound[dependent].year\n",
    "        X_tr, Y_tr, X_te, Y_te = split_train_test(yr_map(X, y_max), yr_map(Y, y_max), col=dependent, sc=scaler)\n",
    "        generator = TimeSeriesSplit(n_splits = (y_max-year_min))\n",
    "        # scoring for selection\n",
    "        if score:  # using de-meaned\n",
    "            rfe = RFECV(estimator=estimat, cv=generator, min_features_to_select=min_feat, scoring=impl_score)\n",
    "        else:\n",
    "            rfe = RFECV(estimator=estimat, cv=generator, min_features_to_select=min_feat, scoring='r2')\n",
    "        # training and filtering\n",
    "        trained = rfe.fit(X_tr.values, Y_tr)   # Feature Selection done on largest training set\n",
    "        cv_results = pd.DataFrame(rfe.cv_results_)\n",
    "        select_regress = np.array(predictors)[trained.get_support()].tolist()\n",
    "        number = int(len(select_regress)) - min_feat\n",
    "        scores[dependent]= cv_results.iloc[number, 2:].to_list()\n",
    "        scores[dependent].append(rfe.score(X_te.values, Y_te))\n",
    "        aggregate[dependent] = np.array(scores[dependent]).mean()\n",
    "        # storing\n",
    "        selected[dependent] = pd.DataFrame({dependent: select_regress}) # storing\n",
    "    if not col:\n",
    "        timer('feature selection (light)', start_time)\n",
    "    store = visualize_selected(selected)\n",
    "    return store, scores, aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "250de648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO WITH SCORES ONLY FOR LAST YEAR (LARGEST TRAINING SET)\n",
    "\n",
    "def lasso_light(X, Y, scaler=False, trans=False):  \n",
    "    alpha = []\n",
    "    aggregate = {x: [] for x in Y.columns}\n",
    "    selected = {x: 0 for x in Y.columns}  # to store variables selected\n",
    "    predictors, dep = X.columns, Y.columns\n",
    "    year_min, year_max = X.index.year.min(), X.index.year.max()\n",
    "    if trans:\n",
    "        X, predictors = transform(trans, X, predictors)  # feature engineering\n",
    "    start_time=timer(None)\n",
    "    for dependent in Y.columns: \n",
    "        y_max = upp_bound[dependent].year\n",
    "        X_tr, Y_tr, X_te, Y_te = split_train_test(yr_map(X, y_max), yr_map(Y, y_max), col=dependent, sc=scaler)\n",
    "        generator = TimeSeriesSplit(n_splits = (y_max - year_min))\n",
    "        # fitting\n",
    "        lasso = LassoCV(cv=generator, selection='cyclic', max_iter=250000, eps=1e-5, tol=5e-4)   # tol=0.0001, eps=1e-3\n",
    "        lasso.fit(X_tr, Y_tr.values.ravel())\n",
    "        alpha.append(lasso.alpha_)\n",
    "        # storing\n",
    "        sel_reg = np.array(predictors)[np.nonzero(lasso.coef_)[0]].tolist()\n",
    "        aggregate[dependent] = lasso.score(X_te, Y_te.values.ravel())\n",
    "        # storing\n",
    "        selected[dependent] = pd.DataFrame({dependent: sel_reg}) # storing\n",
    "        \n",
    "    timer('lasso (light)', start_time)\n",
    "    rank_penalization(alpha)\n",
    "    \n",
    "    store = pd.DataFrame()\n",
    "    for variable, df in selected.items():\n",
    "        store = pd.concat([store, df], axis=1)\n",
    "    store.fillna(value=\"\", inplace=True)   \n",
    "    \n",
    "    return store, aggregate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46888395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
